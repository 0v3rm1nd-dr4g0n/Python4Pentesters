import requests
import re
import sys

if __name__ == "__main__":
    def usage():
        print "%s <url>" % (sys.argv[0])
    if (len(sys.argv) <> 2):
        usage()
        sys.exit(0)

    url = sys.argv[1]

    # issue the HTTP Request for the target page
    page = requests.get(url)

    # You can now view the content of the response via
    # page.content

    # You can then use regular expressions to search the page contents
    # values = re.findall(pattern, page.content
    # print values

    # This is a very simple regex to extract all links from a page
    values = re.findall(ur'(?i)\b((?:https?://|www\d{0,3}[.]|[a-z0-9.\-]+[.][a-z]{2,4}/)(?:[^\s()<>]+|\(([^\s()<>]+|(\([^\s()<>]+\)))*\))+(?:\(([^\s()<>]+|(\([^\s()<>]+\)))*\)|[^\s`!()\[\]{};:\'".,<>?\xab\xbb\u201c\u201d\u2018\u2019]))', page.content)

    # we can unique a list of strings by converting it to a SET and back like this
    values = list(set(values))

    # we can then print the list of links
    for value in values:
        print value
